{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.display import HTML\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from modules.config import DPI, FIG_SIZE\n",
    "from modules.random_walk_monte_carlo import RandomWalker\n",
    "from modules.dla_algorithm import Diffusion, compare_omegas, plot_omega_comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test various $\\eta$\n",
    "We test 3 values of $\\eta = 0,1,2$, and run $200$ growth iterations with the default value of $\\omega = 1.8$.\n",
    "\n",
    "We plot the resulting cluster and concentration of the grid cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 100\n",
    "growth_iterations = 200\n",
    "\n",
    "\n",
    "def run_simulation_and_plot(eta):\n",
    "    diffusion = Diffusion(grid_size, eta, initial_point=\"bottom\")\n",
    "    diffusion.run_simulation(growth_iterations)\n",
    "    diffusion.plot(eta, save=True, filename=f\"diffusion_eta_{eta}_200.png\")\n",
    "\n",
    "\n",
    "_ = Parallel(n_jobs=-2)(delayed(run_simulation_and_plot)(eta) for eta in [0, 1, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find optimal value of $\\omega$\n",
    "Next, we try find the approximate optimal value of $\\omega$ for the three values of $\\eta = 0,1,2$.\n",
    "\n",
    "We test for $\\omega$ in $[1.6, 1.9]$ and run $100$ simulations with $200$ growth iterations for each combination of $\\omega$ and $\\eta$.\n",
    "\n",
    "During each growth step, we solve the Lapsal equation using the **SOR** method and we check the number of iterations we had to do for **SOR** to converge. We then measure the performance of each $\\omega$ by checking the total number of iterations we had to do in **SOR** and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0\n",
    "omegas = [1.6, 1.65, 1.7, 1.75, 1.8, 1.85, 1.9]\n",
    "num_simulations = 100\n",
    "\n",
    "results_omegas_eta_0 = compare_omegas(eta, omegas, num_simulations)\n",
    "plot_omega_comparison(\n",
    "    results_omegas_eta_0, omegas, eta, save=True, filename=\"results/omega_comparison_eta_0.png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 1\n",
    "omegas = [1.6, 1.65, 1.7, 1.75, 1.8, 1.85, 1.9]\n",
    "num_simulations = 100\n",
    "\n",
    "results_omegas_eta_1 = compare_omegas(eta, omegas, num_simulations)\n",
    "plot_omega_comparison(\n",
    "    results_omegas_eta_1, omegas, eta, save=True, filename=\"results/omega_comparison_eta_1.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 2\n",
    "omegas = [1.6, 1.65, 1.7, 1.75, 1.8, 1.85, 1.9]\n",
    "num_simulations = 100\n",
    "\n",
    "results_omegas_eta_2 = compare_omegas(eta, omegas, num_simulations)\n",
    "plot_omega_comparison(\n",
    "    results_omegas_eta_2, omegas, eta, save=True, filename=\"results/omega_comparison_eta_2.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consolidate the results for all three $\\eta$ in one graph by plotting the mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_0 = np.mean(np.array(results_omegas_eta_0), axis=0)\n",
    "stds_0 = np.std(np.array(results_omegas_eta_0), axis=0)\n",
    "\n",
    "means_1 = np.mean(np.array(results_omegas_eta_1), axis=0)\n",
    "stds_1 = np.std(np.array(results_omegas_eta_1), axis=0)\n",
    "\n",
    "means_2 = np.mean(np.array(results_omegas_eta_2), axis=0)\n",
    "stds_2 = np.std(np.array(results_omegas_eta_2), axis=0)\n",
    "\n",
    "plt.figure(figsize=FIG_SIZE, dpi=DPI)\n",
    "plt.errorbar(omegas, means_0, yerr=stds_0, fmt=\"o-\", capsize=5, label=r\"$\\eta = 0$\")\n",
    "plt.errorbar(omegas, means_1, yerr=stds_1, fmt=\"o-\", capsize=5, label=r\"$\\eta = 1$\")\n",
    "plt.errorbar(omegas, means_2, yerr=stds_2, fmt=\"o-\", capsize=5, label=r\"$\\eta = 2$\")\n",
    "plt.xlabel(r\"$\\omega$\")\n",
    "plt.ylabel(\"# SOR Iterations\")\n",
    "plt.title(r\"# iterations needed in SOR vs $\\omega$ for 200 grow steps\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"results/omega_vs_sor_mean.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the cluster shape\n",
    "Lastly, we analyse the shape of the cluster so that we can compare it to the Monte Carlo simulation.\n",
    "\n",
    "We take $10$ values of $\\eta$ from $0$ to $3$ and more or less optimal $\\omega$ for each. We run $100$ simulations with $200$ growth iterations each and measure the size of the perimeter and the width and height of the cluster. We then plot our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 100\n",
    "growth_iterations = 200\n",
    "num_simulations = 100\n",
    "\n",
    "\n",
    "def run_simulation_and_measure(eta, omega):\n",
    "    diffusion = Diffusion(grid_size, eta, initial_point=\"bottom\")\n",
    "    diffusion.run_simulation(growth_iterations, omega)\n",
    "\n",
    "    return [\n",
    "        diffusion.get_perimeter_size(),\n",
    "        diffusion.get_width(),\n",
    "        diffusion.get_height(),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etas = np.linspace(0, 3, 10)\n",
    "omegas = np.linspace(1.65, 1.85, 10)\n",
    "\n",
    "clusters = [[] for _ in range(len(etas))]\n",
    "\n",
    "for i, eta in enumerate(etas):\n",
    "    clusters[i] = np.array(Parallel(n_jobs=-2)(\n",
    "        delayed(run_simulation_and_measure)(eta, omegas[i]) for _ in range(num_simulations)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perimeters = [cluster_eta[:,0] for cluster_eta in clusters]\n",
    "widths = [cluster_eta[:,1] for cluster_eta in clusters]\n",
    "heights = [cluster_eta[:,2] for cluster_eta in clusters]\n",
    "\n",
    "means_perimeter = np.mean(perimeters, axis=1)\n",
    "stds_perimeter = np.std(perimeters, axis=1)\n",
    "\n",
    "means_width = np.mean(widths, axis=1)\n",
    "stds_width = np.std(widths, axis=1)\n",
    "\n",
    "means_height = np.mean(heights, axis=1)\n",
    "stds_height = np.std(heights, axis=1)\n",
    "\n",
    "plt.figure(figsize=FIG_SIZE, dpi=DPI)\n",
    "plt.errorbar(etas, means_perimeter, yerr=stds_perimeter, fmt=\"o-\", capsize=5, label=\"Perimeter\")\n",
    "plt.errorbar(etas, means_width, yerr=stds_width, fmt=\"o-\", capsize=5, label=\"Width\")\n",
    "plt.errorbar(etas, means_height, yerr=stds_height, fmt=\"o-\", capsize=5, label=\"Height\")\n",
    "plt.xlabel(r\"$\\eta$\")\n",
    "plt.ylabel(\"Cluster measurements\")\n",
    "plt.title(r\"Average cluster perimeter, width and height for clusters of size 200\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"results/average_dla_cluster_sizes.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte-Carlo Random Walker\n",
    "\n",
    "For the Monte Carlo Random Walker system, we will be testing under the same conditions ast the DLA, where possible. The one parameter which can be varied, namely $p_{stick}$, will be tested for [0.25, 0.5, 0.75, 1]. Similarly, we will be investigating the height, width, and perimeter of the resulting clusters. \n",
    "\n",
    "Disclaimer: generating the results may take up to 1 hour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 100\n",
    "steps = 10000000\n",
    "num_simulations = 20\n",
    "p_stick_values = [0.25, 0.5, 0.75, 1]\n",
    "\n",
    "def run_single_simulation(p_stick, steps, grid_size):\n",
    "    simulation = RandomWalker(N=grid_size, p_stick=p_stick, initial_point=\"bottom\")\n",
    "    simulation.run_simulation(steps)\n",
    "    return simulation, len(simulation.cluster), simulation.get_perimeter_size(), simulation.get_width(), simulation.get_height()\n",
    "\n",
    "results = []\n",
    "final_simulations = {}\n",
    "\n",
    "for p_stick in p_stick_values:\n",
    "    cluster_sizes, perimeter_sizes, widths, heights = [], [], [], []\n",
    "\n",
    "    for _ in tqdm(range(num_simulations), desc=f\"Running p_stick={p_stick}\", leave=True):\n",
    "        simulation, cluster_size, perimeter_size, width, height = run_single_simulation(p_stick, steps, grid_size)\n",
    "\n",
    "        cluster_sizes.append(cluster_size)\n",
    "        perimeter_sizes.append(perimeter_size)\n",
    "        widths.append(width)\n",
    "        heights.append(height)\n",
    "\n",
    "    final_simulations[p_stick] = simulation\n",
    "\n",
    "    results.append({\n",
    "        \"p_stick\": p_stick,\n",
    "        \"mean_cluster_size\": np.mean(cluster_sizes),\n",
    "        \"std_cluster_size\": np.std(cluster_sizes),\n",
    "        \"mean_perimeter_size\": np.mean(perimeter_sizes),\n",
    "        \"std_perimeter_size\": np.std(perimeter_sizes),\n",
    "        \"mean_width\": np.mean(widths),\n",
    "        \"std_width\": np.std(widths),\n",
    "        \"mean_height\": np.mean(heights),\n",
    "        \"std_height\": np.std(heights),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"data/random_walk_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p_stick, simulation in final_simulations.items():\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "    fixed_grid = np.where(simulation.grid == -1, 1, simulation.grid)\n",
    "\n",
    "    norm_grid = (fixed_grid - np.min(fixed_grid)) / (np.max(fixed_grid) - np.min(fixed_grid))\n",
    "\n",
    "    im = ax.imshow(norm_grid, cmap=\"Blues\", alpha=0.8)\n",
    "\n",
    "    gradient = np.linspace(0, 1, simulation.grid.shape[0])[:, None]  # Vertical gradient\n",
    "    ax.imshow(gradient, cmap=\"Blues\", alpha=0.3)\n",
    "\n",
    "    x_points = [coords[1] for coords in simulation.cluster]\n",
    "    y_points = [coords[0] for coords in simulation.cluster]\n",
    "    ax.scatter(x_points, y_points, color=\"black\", s=3)\n",
    "    ax.set_title(r\"Random Walker grid with $P_{stick} = $\" + f\"{p_stick}\")\n",
    "\n",
    "    plt.colorbar(im)\n",
    "    plt.savefig(f\"results/cluster_pstick_{p_stick}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p_stick_values = df[\"p_stick\"].values \n",
    "\n",
    "\n",
    "mean_cluster_sizes = df[\"mean_cluster_size\"].values\n",
    "std_cluster_sizes = df[\"std_cluster_size\"].values\n",
    "\n",
    "mean_perimeter_sizes = df[\"mean_perimeter_size\"].values\n",
    "std_perimeter_sizes = df[\"std_perimeter_size\"].values\n",
    "\n",
    "mean_widths = df[\"mean_width\"].values\n",
    "std_widths = df[\"std_width\"].values\n",
    "\n",
    "mean_heights = df[\"mean_height\"].values\n",
    "std_heights = df[\"std_height\"].values\n",
    "\n",
    "\n",
    "plt.figure(figsize=FIG_SIZE, dpi=DPI)\n",
    "plt.errorbar(p_stick_values, mean_perimeter_sizes, yerr=std_perimeter_sizes, fmt='s-', capsize=5, label=r'Perimeter Size', color=\"orange\")\n",
    "plt.errorbar(p_stick_values, mean_widths, yerr=std_widths, fmt='^-', capsize=5, label=r'Width', color=\"green\")\n",
    "plt.errorbar(p_stick_values, mean_heights, yerr=std_heights, fmt='v-', capsize=5, label=r'Height', color=\"red\")\n",
    "\n",
    "plt.xlabel(r'$P_{stick}$')\n",
    "plt.ylabel('Simulation Metrics')\n",
    "plt.title(r'Comparison of Cluster Metrics vs $P_{stick}$ for 100x100 Grid')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(f\"results/RW_cluster_metrics.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "# Chemical Reaction Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.gray_scott import create_gif, simulate_gray_scott"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "steps = 3_000\n",
    "\n",
    "Du = 0.16\n",
    "Dv = 0.08\n",
    "F = 0.035\n",
    "k = 0.06\n",
    "dx = 1\n",
    "dt = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_gray_scott(\n",
    "    N,\n",
    "    Du,\n",
    "    Dv,\n",
    "    F,\n",
    "    k,\n",
    "    dx,\n",
    "    dt,\n",
    "    steps,\n",
    "    chemical=\"v\",\n",
    "    boundary=\"neumann\",\n",
    "    info=True,\n",
    "    noise_u=True,\n",
    "    noise_v=False,\n",
    ")\n",
    "create_gif(\"results\", \"results/gray_scott1.gif\")\n",
    "HTML('<img src=\"results/gray_scott1.gif\">')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_gray_scott(\n",
    "    N,\n",
    "    Du,\n",
    "    Dv,\n",
    "    F,\n",
    "    k,\n",
    "    dx,\n",
    "    dt,\n",
    "    steps,\n",
    "    chemical=\"v\",\n",
    "    boundary=\"neumann\",\n",
    "    info=True,\n",
    ")\n",
    "create_gif(\"results\", \"results/gray_scott2.gif\")\n",
    "HTML('<img src=\"results/gray_scott2.gif\">')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Du = 0.02\n",
    "Dv = 0.01\n",
    "F = 0.034\n",
    "k = 0.095\n",
    "dx = 0.1\n",
    "dt = 0.1\n",
    "\n",
    "simulate_gray_scott(\n",
    "    N, Du, Dv, F, k, dx, dt, steps, chemical=\"u\", boundary=\"neumann\", info=True\n",
    ")\n",
    "create_gif(\"results\", \"results/gray_scott3.gif\")\n",
    "HTML('<img src=\"results/gray_scott3.gif\">')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Du = 0.01\n",
    "Dv = 0.005\n",
    "F = 0.04\n",
    "k = 0.06\n",
    "dx = 1\n",
    "dt = 0.1\n",
    "\n",
    "simulate_gray_scott(\n",
    "    N, Du, Dv, F, k, dx, dt, steps, chemical=\"u\", boundary=\"neumann\", info=True\n",
    ")\n",
    "create_gif(\"results\", \"results/gray_scott4.gif\")\n",
    "HTML('<img src=\"results/gray_scott4.gif\">')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scicomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
